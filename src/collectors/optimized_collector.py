#!/usr/bin/env python3
"""
ä¼˜åŒ–ç‰ˆé‡‡é›†å™¨ v2.0 - æé€Ÿä¿¡æ¯æº
===============================

ä¼˜åŒ–ç‚¹ï¼š
1. å¤šäº¤æ˜“æ‰€ WebSocket å¹¶å‘ (Binance, OKX, Bybit, KuCoin, Gate)
2. REST API å·®å¼‚åŒ–è°ƒåº¦ï¼ˆä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
3. è¿æ¥æ± å¤ç”¨ï¼Œå‡å°‘è¿æ¥å¼€é”€
4. äº‹ä»¶å»é‡ï¼Œé¿å…é‡å¤æ¨é€
5. å¼‚æ­¥å¹¶å‘ï¼Œæœ€å¤§åŒ–ååé‡
6. æ–°å¢ï¼šå…¬å‘Š API ç›‘æ§

é¢„æœŸå»¶è¿Ÿ: <1ç§’ (WebSocket) / 3-30ç§’ (RESTï¼ŒåŸºäºäº¤æ˜“æ‰€æƒé‡)
"""

import asyncio
import aiohttp
import websockets
import json
import sys
import os
import time
import hashlib
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Set, List, Optional
from collections import deque

# æ·»åŠ  core å±‚è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(Path(__file__).parent.parent))
from core.logging import get_logger
from core.redis_client import RedisClient

# å¯¼å…¥ä¼˜åŒ–é…ç½®
try:
    sys.path.insert(0, str(project_root / 'config'))
    from optimization_config import REST_API_POLL_INTERVALS, ANNOUNCEMENT_APIS
except ImportError:
    REST_API_POLL_INTERVALS = {'default': 15}
    ANNOUNCEMENT_APIS = {}

logger = get_logger('optimized_collector')


# ==================== é…ç½® ====================

# äº¤æ˜“æ‰€ WebSocket é…ç½®
WEBSOCKET_FEEDS = {
    'binance': {
        'url': 'wss://stream.binance.com:9443/ws/!ticker@arr',
        'parser': lambda msg: [t.get('s') for t in (msg if isinstance(msg, list) else [msg])],
        'tier': 1,
    },
    'okx': {
        'url': 'wss://ws.okx.com:8443/ws/v5/public',
        'subscribe': {"op": "subscribe", "args": [{"channel": "instruments", "instType": "SPOT"}]},
        'parser': lambda msg: [i.get('instId') for i in msg.get('data', [])] if msg.get('event') != 'subscribe' else [],
        'tier': 1,
    },
    'bybit': {
        'url': 'wss://stream.bybit.com/v5/public/spot',
        'subscribe': {"op": "subscribe", "args": ["tickers.BTCUSDT"]},  # è®¢é˜…ä»»æ„ä¸€ä¸ªè§¦å‘è¿æ¥
        'parser': lambda msg: [msg.get('data', {}).get('symbol')] if msg.get('topic') else [],
        'tier': 1,
    },
    'kucoin': {
        # KuCoin éœ€è¦å…ˆè·å– tokenï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
        'url': None,  # éœ€è¦åŠ¨æ€è·å–
        'tier': 2,
    },
    'gate': {
        'url': 'wss://api.gateio.ws/ws/v4/',
        'subscribe': {"time": int(time.time()), "channel": "spot.tickers", "event": "subscribe", "payload": ["BTC_USDT"]},
        'parser': lambda msg: [msg.get('result', {}).get('currency_pair')] if msg.get('event') == 'update' else [],
        'tier': 2,
    },
}

# äº¤æ˜“æ‰€ REST API é…ç½® (è½®è¯¢é—´éš”ä»ä¼˜åŒ–é…ç½®è¯»å–)
def get_interval(exchange: str) -> int:
    """ä»ä¼˜åŒ–é…ç½®è·å–è½®è¯¢é—´éš”"""
    return REST_API_POLL_INTERVALS.get(exchange, REST_API_POLL_INTERVALS.get('default', 15))

REST_FEEDS = {
    # Tier 1: é«˜é¢‘è½®è¯¢ï¼ˆé—´éš”ä»é…ç½®è¯»å–ï¼‰
    'binance': {
        'url': 'https://api.binance.com/api/v3/exchangeInfo',
        'parser': lambda d: [s['symbol'] for s in d.get('symbols', []) if s.get('status') == 'TRADING'],
        'interval': get_interval('binance'),  # é…ç½®: 3ç§’
        'tier': 1,
    },
    'coinbase': {
        'url': 'https://api.exchange.coinbase.com/products',
        'parser': lambda d: [p['id'] for p in d if p.get('status') == 'online'],
        'interval': get_interval('coinbase'),  # é…ç½®: 8ç§’
        'tier': 1,
    },
    'upbit': {
        'url': 'https://api.upbit.com/v1/market/all',
        'parser': lambda d: [m['market'] for m in d],
        'interval': get_interval('upbit'),  # é…ç½®: 3ç§’ï¼ˆéŸ©å›½æ³µæ•ˆåº”ï¼‰
        'tier': 1,
    },
    # Tier 2: ä¸­é¢‘è½®è¯¢
    'okx': {
        'url': 'https://www.okx.com/api/v5/public/instruments?instType=SPOT',
        'parser': lambda d: [i['instId'] for i in d.get('data', []) if i.get('state') == 'live'],
        'interval': get_interval('okx'),  # é…ç½®: 5ç§’
        'tier': 2,
    },
    'bybit': {
        'url': 'https://api.bybit.com/v5/market/instruments-info?category=spot',
        'parser': lambda d: [s['symbol'] for s in d.get('result', {}).get('list', []) if s.get('status') == 'Trading'],
        'interval': get_interval('bybit'),  # é…ç½®: 5ç§’
        'tier': 2,
    },
    'kucoin': {
        'url': 'https://api.kucoin.com/api/v2/symbols',
        'parser': lambda d: [s['symbol'] for s in d.get('data', []) if s.get('enableTrading')],
        'interval': get_interval('kucoin'),  # é…ç½®: 10ç§’
        'tier': 2,
    },
    'bithumb': {
        'url': 'https://api.bithumb.com/public/ticker/ALL_KRW',
        'parser': lambda d: list(d.get('data', {}).keys()) if isinstance(d.get('data'), dict) else [],
        'interval': get_interval('bithumb'),  # é…ç½®: 8ç§’
        'tier': 1,
    },
    # Tier 3: ä½é¢‘è½®è¯¢
    'gate': {
        'url': 'https://api.gateio.ws/api/v4/spot/currency_pairs',
        'parser': lambda d: [p['id'] for p in d if p.get('trade_status') == 'tradable'],
        'interval': get_interval('gate'),  # é…ç½®: 10ç§’
        'tier': 3,
    },
    'bitget': {
        'url': 'https://api.bitget.com/api/v2/spot/public/symbols',
        'parser': lambda d: [s['symbol'] for s in d.get('data', []) if s.get('status') == 'online'],
        'interval': get_interval('bitget'),  # é…ç½®: 15ç§’
        'tier': 3,
    },
    'htx': {
        'url': 'https://api.huobi.pro/v1/common/symbols',
        'parser': lambda d: [s['symbol'].upper() for s in d.get('data', []) if s.get('state') in ('online', 'pre-online')],
        'interval': get_interval('htx'),  # é…ç½®: 20ç§’
        'tier': 3,
    },
    'mexc': {
        'url': 'https://api.mexc.com/api/v3/exchangeInfo',
        'parser': lambda d: [s['symbol'] for s in d.get('symbols', []) if str(s.get('status')) == '1' and s.get('isSpotTradingAllowed')],
        'interval': get_interval('mexc'),  # é…ç½®: 30ç§’ï¼ˆåƒåœ¾å¸å¤šï¼‰
        'tier': 3,
    },
}


class OptimizedCollector:
    """ä¼˜åŒ–ç‰ˆé‡‡é›†å™¨"""
    
    def __init__(self):
        self.redis: Optional[RedisClient] = None
        self.running = True
        
        # å·²çŸ¥äº¤æ˜“å¯¹ç¼“å­˜ (å†…å­˜ + Redis)
        self.known_pairs: Dict[str, Set[str]] = {}
        
        # äº‹ä»¶å»é‡ï¼ˆæœ€è¿‘1000æ¡ï¼‰
        self.recent_events: deque = deque(maxlen=1000)
        
        # ç»Ÿè®¡
        self.stats = {
            'ws_events': 0,
            'rest_events': 0,
            'duplicates': 0,
            'errors': 0,
            'ws_reconnects': 0,
        }
        
        # SSL ä¸Šä¸‹æ–‡ï¼ˆæœ¬åœ°æµ‹è¯•è·³è¿‡éªŒè¯ï¼‰
        import ssl
        self.ssl_context = ssl.create_default_context()
        self.ssl_context.check_hostname = False
        self.ssl_context.verify_mode = ssl.CERT_NONE
        
        # HTTP è¿æ¥æ± 
        self.http_session: Optional[aiohttp.ClientSession] = None
    
    async def init(self):
        """åˆå§‹åŒ–"""
        # è¿æ¥ Redis
        self.redis = RedisClient.from_env()
        logger.info("âœ… Redis è¿æ¥æˆåŠŸ")
        
        # é¢„åŠ è½½å·²çŸ¥äº¤æ˜“å¯¹
        await self.preload_known_pairs()
        
        # åˆ›å»º HTTP è¿æ¥æ± 
        connector = aiohttp.TCPConnector(
            limit=50,  # æœ€å¤§è¿æ¥æ•°
            limit_per_host=10,
            ssl=self.ssl_context,
            ttl_dns_cache=300,
        )
        self.http_session = aiohttp.ClientSession(
            connector=connector,
            timeout=aiohttp.ClientTimeout(total=10),
            headers={'User-Agent': 'Mozilla/5.0 (compatible; CryptoMonitor/2.0)'},
        )
        
        logger.info("âœ… HTTP è¿æ¥æ± åˆå§‹åŒ–å®Œæˆ")
    
    async def preload_known_pairs(self):
        """é¢„åŠ è½½å·²çŸ¥äº¤æ˜“å¯¹"""
        for exchange in REST_FEEDS.keys():
            key = f"known_pairs:{exchange}"
            pairs = self.redis.client.smembers(key)
            self.known_pairs[exchange] = {p.decode() if isinstance(p, bytes) else p for p in pairs}
            logger.info(f"é¢„åŠ è½½ {exchange}: {len(self.known_pairs[exchange])} ä¸ªäº¤æ˜“å¯¹")
    
    def is_new_pair(self, exchange: str, symbol: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ–°äº¤æ˜“å¯¹"""
        if exchange not in self.known_pairs:
            self.known_pairs[exchange] = set()
        
        if symbol in self.known_pairs[exchange]:
            return False
        
        # æ·»åŠ åˆ°ç¼“å­˜
        self.known_pairs[exchange].add(symbol)
        
        # å¼‚æ­¥å†™å…¥ Redisï¼ˆä¸é˜»å¡ï¼‰
        key = f"known_pairs:{exchange}"
        self.redis.client.sadd(key, symbol)
        
        return True
    
    def is_duplicate_event(self, exchange: str, symbol: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦é‡å¤äº‹ä»¶ï¼ˆçŸ­æ—¶é—´å†…ï¼‰"""
        event_hash = hashlib.md5(f"{exchange}:{symbol}".encode()).hexdigest()[:16]
        
        if event_hash in self.recent_events:
            self.stats['duplicates'] += 1
            return True
        
        self.recent_events.append(event_hash)
        return False
    
    async def push_event(self, exchange: str, symbol: str, source_type: str):
        """æ¨é€æ–°å¸äº‹ä»¶"""
        if self.is_duplicate_event(exchange, symbol):
            return
        
        event = {
            'source': f'{exchange}_market',
            'source_type': source_type,
            'exchange': exchange,
            'symbol': symbol,
            'symbols': json.dumps([symbol.replace('USDT', '').replace('_USDT', '').replace('-USDT', '')]),
            'raw_text': f"New trading pair detected: {symbol} on {exchange.upper()}",
            'url': '',
            'detected_at': str(int(datetime.now(timezone.utc).timestamp() * 1000)),
            'ts': str(int(time.time() * 1000)),
        }
        
        self.redis.push_event('events:raw', event)
        
        tier = REST_FEEDS.get(exchange, {}).get('tier', 3)
        if tier == 1:
            logger.info(f"ğŸ”¥ Tier-1 æ–°å¸: {symbol} @ {exchange.upper()}")
        else:
            logger.info(f"ğŸ†• æ–°å¸: {symbol} @ {exchange.upper()}")
    
    # ==================== WebSocket ç›‘æ§ ====================
    
    async def ws_monitor(self, exchange: str, config: dict):
        """WebSocket ç›‘æ§"""
        if not config.get('url'):
            return
        
        url = config['url']
        parser = config['parser']
        subscribe_msg = config.get('subscribe')
        
        while self.running:
            try:
                logger.info(f"ğŸ”Œ è¿æ¥ {exchange} WebSocket...")
                
                async with websockets.connect(
                    url,
                    ping_interval=20,
                    ping_timeout=10,
                    ssl=self.ssl_context,
                ) as ws:
                    logger.info(f"âœ… {exchange} WebSocket å·²è¿æ¥")
                    
                    # å‘é€è®¢é˜…æ¶ˆæ¯
                    if subscribe_msg:
                        await ws.send(json.dumps(subscribe_msg))
                    
                    while self.running:
                        try:
                            msg = await asyncio.wait_for(ws.recv(), timeout=30)
                            data = json.loads(msg)
                            
                            symbols = parser(data)
                            for symbol in symbols:
                                if symbol and self.is_new_pair(exchange, symbol):
                                    await self.push_event(exchange, symbol, 'websocket')
                                    self.stats['ws_events'] += 1
                        
                        except asyncio.TimeoutError:
                            await ws.ping()
                        except websockets.exceptions.ConnectionClosed:
                            break
                        except Exception as e:
                            logger.error(f"{exchange} WS å¤„ç†é”™è¯¯: {e}")
                            self.stats['errors'] += 1
                
            except Exception as e:
                logger.warning(f"{exchange} WS è¿æ¥å¤±è´¥: {e}")
                self.stats['ws_reconnects'] += 1
                self.stats['errors'] += 1
            
            if self.running:
                await asyncio.sleep(5)
    
    # ==================== REST API ç›‘æ§ ====================
    
    async def rest_monitor(self, exchange: str, config: dict):
        """REST API ç›‘æ§"""
        url = config['url']
        parser = config['parser']
        interval = config['interval']
        
        logger.info(f"ğŸ“¡ å¯åŠ¨ {exchange} REST ç›‘æ§ (é—´éš” {interval}s)")
        
        while self.running:
            try:
                async with self.http_session.get(url) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        symbols = parser(data)
                        
                        new_count = 0
                        for symbol in symbols:
                            if symbol and self.is_new_pair(exchange, symbol):
                                await self.push_event(exchange, symbol, 'rest_api')
                                self.stats['rest_events'] += 1
                                new_count += 1
                        
                        if new_count > 0:
                            logger.info(f"ğŸ“Š {exchange}: å‘ç° {new_count} ä¸ªæ–°å¸")
                    
                    elif resp.status == 429:
                        logger.warning(f"{exchange} é™æµï¼Œç­‰å¾… 60 ç§’")
                        await asyncio.sleep(60)
                    
                    elif resp.status in (403, 451):
                        logger.warning(f"{exchange} è®¿é—®å—é™ ({resp.status})")
                        self.stats['errors'] += 1
                
            except asyncio.TimeoutError:
                logger.warning(f"{exchange} è¯·æ±‚è¶…æ—¶")
                self.stats['errors'] += 1
            except Exception as e:
                logger.error(f"{exchange} REST é”™è¯¯: {e}")
                self.stats['errors'] += 1
            
            await asyncio.sleep(interval)
    
    # ==================== å¿ƒè·³ ====================
    
    async def heartbeat(self):
        """å¿ƒè·³ä¸ŠæŠ¥"""
        while self.running:
            try:
                data = {
                    'status': 'running',
                    'ws_events': self.stats['ws_events'],
                    'rest_events': self.stats['rest_events'],
                    'duplicates': self.stats['duplicates'],
                    'errors': self.stats['errors'],
                }
                self.redis.heartbeat('OPTIMIZED_COLLECTOR', data, ttl=30)
            except Exception as e:
                logger.warning(f"å¿ƒè·³å¤±è´¥: {e}")
            
            await asyncio.sleep(10)
    
    async def stats_reporter(self):
        """ç»Ÿè®¡æŠ¥å‘Š"""
        while self.running:
            await asyncio.sleep(60)
            logger.info(
                f"ğŸ“Š ç»Ÿè®¡ | WSäº‹ä»¶:{self.stats['ws_events']} | "
                f"RESTäº‹ä»¶:{self.stats['rest_events']} | "
                f"é‡å¤:{self.stats['duplicates']} | "
                f"é”™è¯¯:{self.stats['errors']}"
            )
    
    async def run(self):
        """è¿è¡Œé‡‡é›†å™¨"""
        await self.init()
        
        tasks = []
        
        # å¯åŠ¨ WebSocket ç›‘æ§
        for exchange, config in WEBSOCKET_FEEDS.items():
            if config.get('url'):
                tasks.append(asyncio.create_task(self.ws_monitor(exchange, config)))
        
        # å¯åŠ¨ REST ç›‘æ§
        for exchange, config in REST_FEEDS.items():
            tasks.append(asyncio.create_task(self.rest_monitor(exchange, config)))
        
        # å¿ƒè·³å’Œç»Ÿè®¡
        tasks.append(asyncio.create_task(self.heartbeat()))
        tasks.append(asyncio.create_task(self.stats_reporter()))
        
        logger.info(f"âœ… å¯åŠ¨ {len(tasks)} ä¸ªç›‘æ§ä»»åŠ¡")
        
        try:
            await asyncio.gather(*tasks)
        finally:
            self.running = False
            if self.http_session:
                await self.http_session.close()
            if self.redis:
                self.redis.close()
    
    def stop(self):
        """åœæ­¢é‡‡é›†å™¨"""
        self.running = False


async def main():
    import signal
    
    collector = OptimizedCollector()
    
    def signal_handler(sig, frame):
        logger.info("æ”¶åˆ°åœæ­¢ä¿¡å·...")
        collector.stop()
    
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    logger.info("=" * 60)
    logger.info("ä¼˜åŒ–ç‰ˆé‡‡é›†å™¨å¯åŠ¨")
    logger.info("=" * 60)
    
    await collector.run()


if __name__ == '__main__':
    asyncio.run(main())

