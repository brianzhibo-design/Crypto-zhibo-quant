#!/usr/bin/env python3
"""
å®æ—¶ä¸Šå¸ä¿¡æ¯ç›‘æ§å™¨
==================

å¤šæ¸ é“å®æ—¶è·å–äº¤æ˜“æ‰€ä¸Šå¸ä¿¡æ¯ï¼š

1. äº¤æ˜“æ‰€å®˜æ–¹ API
   - å…¬å‘Š API (Binance, OKX, Bybit, KuCoin ç­‰)
   - å¸‚åœº API (æ£€æµ‹æ–°äº¤æ˜“å¯¹)
   - WebSocket (å®æ—¶æ¨é€)

2. ç¤¾äº¤åª’ä½“
   - Twitter/X (å®˜æ–¹è´¦å·)
   - Telegram (å®˜æ–¹é¢‘é“)
   - Discord (Webhook)

3. æ–°é—»èšåˆ
   - RSS è®¢é˜…
   - æ–°é—» API

å»¶è¿Ÿç›®æ ‡: <10ç§’ (å…¬å‘Š) / <1ç§’ (WebSocket)
"""

import asyncio
import aiohttp
import ssl
import json
import re
import time
import hashlib
import sys
import os
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Set, Optional
from dataclasses import dataclass
from enum import Enum

sys.path.insert(0, str(Path(__file__).parent.parent))

from core.logging import get_logger
from core.redis_client import RedisClient
from core.utils import extract_contract_address

logger = get_logger('realtime_listing')


# ==================== æ•°æ®æºé…ç½® ====================

class SourceType(Enum):
    ANNOUNCEMENT = "announcement"      # å®˜æ–¹å…¬å‘Š
    MARKET_API = "market_api"          # å¸‚åœº API
    WEBSOCKET = "websocket"            # WebSocket
    TWITTER = "twitter"                # Twitter
    TELEGRAM = "telegram"              # Telegram
    RSS = "rss"                        # RSS è®¢é˜…
    NEWS = "news"                      # æ–°é—» API


@dataclass
class ListingEvent:
    """ä¸Šå¸äº‹ä»¶"""
    source: str
    source_type: SourceType
    exchange: str
    symbol: str
    title: str
    url: str
    timestamp: int
    contract_address: str = ""
    chain: str = ""
    raw_data: dict = None


# ==================== äº¤æ˜“æ‰€å…¬å‘Š API ====================

ANNOUNCEMENT_APIS = {
    'binance': {
        'url': 'https://www.binance.com/bapi/composite/v1/public/cms/article/list/query',
        'method': 'POST',
        'payload': {
            "type": 1,
            "pageNo": 1,
            "pageSize": 20,
            "catalogId": 48
        },
        'parser': lambda d: [
            {
                'id': item.get('id'),
                'title': item.get('title', ''),
                'url': f"https://www.binance.com/en/support/announcement/{item.get('code', '')}",
                'time': item.get('releaseDate', 0),
            }
            for item in d.get('data', {}).get('catalogs', [{}])[0].get('articles', [])
        ],
        'keywords': ['will list', 'new listing', 'adds', 'launches'],
        'interval': 5,  # 5ç§’è½®è¯¢
    },
    
    'okx': {
        'url': 'https://www.okx.com/v2/support/home/web?t=1',
        'method': 'GET',
        'parser': lambda d: [
            {
                'id': item.get('articleId'),
                'title': item.get('title', ''),
                'url': f"https://www.okx.com/support/hc/articles/{item.get('articleId', '')}",
                'time': item.get('publishTime', 0),
            }
            for item in d.get('data', {}).get('announcementList', [])
        ],
        'keywords': ['listing', 'new token', 'adds', 'launches'],
        'interval': 5,
    },
    
    'bybit': {
        'url': 'https://api.bybit.com/v5/announcements/index',
        'method': 'GET',
        'params': {'locale': 'en-US', 'type': 'new_crypto'},
        'parser': lambda d: [
            {
                'id': item.get('id'),
                'title': item.get('title', ''),
                'url': item.get('url', ''),
                'time': item.get('dateTimestamp', 0),
            }
            for item in d.get('result', {}).get('list', [])
        ],
        'keywords': ['list', 'new', 'launches'],
        'interval': 5,
    },
    
    'kucoin': {
        'url': 'https://www.kucoin.com/_api/cms/articles',
        'method': 'GET',
        'params': {'page': 1, 'pageSize': 20, 'category': 'listing'},
        'parser': lambda d: [
            {
                'id': item.get('id'),
                'title': item.get('title', ''),
                'url': f"https://www.kucoin.com/news/{item.get('seoUrl', '')}",
                'time': item.get('createdAt', 0),
            }
            for item in d.get('items', [])
        ],
        'keywords': ['list', 'new', 'trading'],
        'interval': 5,
    },
    
    'gate': {
        'url': 'https://www.gate.io/api/v1/announcement/list',
        'method': 'GET',
        'params': {'page': 1, 'limit': 20, 'category': 'listing'},
        'parser': lambda d: [
            {
                'id': item.get('id'),
                'title': item.get('title', ''),
                'url': f"https://www.gate.io/article/{item.get('id', '')}",
                'time': item.get('createdAt', 0) * 1000,
            }
            for item in d.get('data', [])
        ],
        'keywords': ['list', 'new', 'launches'],
        'interval': 10,
    },
    
    'bitget': {
        'url': 'https://api.bitget.com/api/v2/public/annoucements',
        'method': 'GET',
        'params': {'language': 'en_US', 'annType': 'coin_listings'},
        'parser': lambda d: [
            {
                'id': item.get('annId'),
                'title': item.get('annTitle', ''),
                'url': item.get('annUrl', ''),
                'time': int(item.get('cTime', 0)),
            }
            for item in d.get('data', [])
        ],
        'keywords': [],  # å·²ç»æŒ‰ç±»å‹è¿‡æ»¤
        'interval': 10,
    },
    
    'mexc': {
        'url': 'https://www.mexc.com/api/platform/spot/market/announcement/list',
        'method': 'GET',
        'params': {'pageNum': 1, 'pageSize': 20, 'type': 1},
        'parser': lambda d: [
            {
                'id': item.get('id'),
                'title': item.get('title', ''),
                'url': f"https://www.mexc.com/support/articles/{item.get('id', '')}",
                'time': item.get('createTime', 0),
            }
            for item in d.get('data', {}).get('list', [])
        ],
        'keywords': ['list', 'new'],
        'interval': 15,  # MEXC ä½ä¼˜å…ˆçº§
    },
    
    # éŸ©å›½äº¤æ˜“æ‰€
    'upbit': {
        'url': 'https://api-manager.upbit.com/api/v1/announcements',
        'method': 'GET',
        'params': {'page': 1, 'per_page': 20},
        'parser': lambda d: [
            {
                'id': item.get('id'),
                'title': item.get('title', ''),
                'url': f"https://upbit.com/service_center/notice?id={item.get('id', '')}",
                'time': int(datetime.fromisoformat(item.get('created_at', '2000-01-01').replace('Z', '+00:00')).timestamp() * 1000) if item.get('created_at') else 0,
            }
            for item in d.get('data', {}).get('list', [])
        ],
        'keywords': ['ì›í™” ë§ˆì¼“', 'KRW', 'ì‹ ê·œ', 'ìƒì¥', 'listing'],
        'interval': 3,  # éŸ©å›½äº¤æ˜“æ‰€é‡è¦
    },
    
    'bithumb': {
        'url': 'https://cafe.bithumb.com/customer/notice',
        'method': 'GET',
        'params': {'pageNo': 1, 'pageSize': 20},
        'parser': lambda d: [
            {
                'id': item.get('no'),
                'title': item.get('title', ''),
                'url': f"https://cafe.bithumb.com/customer/notice/{item.get('no', '')}",
                'time': item.get('regDt', 0),
            }
            for item in d.get('data', {}).get('list', [])
        ],
        'keywords': ['ì‹ ê·œ', 'ìƒì¥', 'KRW', 'listing'],
        'interval': 3,
    },
}


# ==================== Twitter å®˜æ–¹è´¦å· ====================

TWITTER_ACCOUNTS = {
    'binance': '@binance',
    'coinbase': '@coinaborase',
    'okx': '@okx',
    'bybit': '@Bybit_Official',
    'kucoin': '@kaborucoin',
    'gate': '@gate_io',
    'bitget': '@bitaborget',
    'upbit': '@Official_Upbit',
}


# ==================== Telegram é¢‘é“ ====================

TELEGRAM_CHANNELS = {
    # äº¤æ˜“æ‰€å®˜æ–¹
    'exchange_official': [
        '@binance_announcements',
        '@Bybit_Announcements', 
        '@okx_announcements',
        '@KuCoin_News',
        '@gateio_ann',
        '@bitget_announcements',
        '@mexcglobal',
        '@HTX_announcements',
    ],
    # ä¸­æ–‡å¿«è®¯ (æ–¹ç¨‹å¼æ–°é—»)
    'news_cn': [
        '@BWEnews',               # ğŸ”¥ æ–¹ç¨‹å¼æ–°é—» - é€Ÿåº¦æœ€å¿«çš„åè¯­åª’ä½“
        '@coinlive_zh',           # Coinlive ä¸­æ–‡
        '@panewscn',              # PANews ä¸­æ–‡
        '@odaily_news',           # Odaily æ˜Ÿçƒæ—¥æŠ¥
        '@BlockBeatsAsia',        # BlockBeats å¾‹åŠ¨
        '@chaincatcher_news',     # ChainCatcher é“¾æ•æ‰‹
        '@foresightnews',         # Foresight News
        '@wublockchain',          # å´è¯´åŒºå—é“¾
        '@theblockbeats',         # The BlockBeats
    ],
    # è‹±æ–‡å¿«è®¯
    'news_en': [
        '@coindesk',
        '@cointelegraph', 
        '@theblock_news',
        '@decryptmedia',
        '@cryptonews_official',
    ],
    # Alpha/ç ”ç©¶
    'alpha': [
        '@hsakatrades',
        '@Croissant_eth',
        '@lookonchain',
        '@spotonchain',
        '@nansen_ai',
    ],
    # é²¸é±¼/é“¾ä¸Šç›‘æ§
    'whale': [
        '@whale_alert_io',
        '@lookonchain',
        '@spotonchain',
        '@arkham',
    ],
    # éŸ©å›½é¢‘é“
    'korean': [
        '@upbit_official',
        '@bithumb_global',
        '@coinone_official',
    ],
    # é¡¹ç›®å®˜æ–¹
    'project': [
        '@SolanaNews',
        '@ethereum',
        '@base',
        '@arbitrum',
    ],
}


class RealtimeListingMonitor:
    """å®æ—¶ä¸Šå¸ç›‘æ§å™¨"""
    
    def __init__(self):
        self.redis: Optional[RedisClient] = None
        self.running = True
        self.seen_announcements: Dict[str, Set[str]] = {}  # exchange -> set of announcement IDs
        
        # SSL ä¸Šä¸‹æ–‡
        self.ssl_context = ssl.create_default_context()
        self.ssl_context.check_hostname = False
        self.ssl_context.verify_mode = ssl.CERT_NONE
        
        # HTTP Session
        self.session: Optional[aiohttp.ClientSession] = None
        
        # ç»Ÿè®¡
        self.stats = {
            'announcements_checked': 0,
            'new_listings_found': 0,
            'errors': 0,
        }
    
    async def init(self):
        """åˆå§‹åŒ–"""
        self.redis = RedisClient.from_env()
        logger.info("âœ… Redis è¿æ¥æˆåŠŸ")
        
        connector = aiohttp.TCPConnector(
            limit=30,
            ssl=self.ssl_context,
        )
        self.session = aiohttp.ClientSession(
            connector=connector,
            timeout=aiohttp.ClientTimeout(total=15),
            headers={'User-Agent': 'Mozilla/5.0 (compatible; CryptoMonitor/2.0)'},
        )
        
        # é¢„åŠ è½½å·²è§å…¬å‘Š
        for exchange in ANNOUNCEMENT_APIS.keys():
            key = f"seen_announcements:{exchange}"
            ids = self.redis.client.smembers(key)
            self.seen_announcements[exchange] = {
                i.decode() if isinstance(i, bytes) else i for i in ids
            }
            logger.info(f"é¢„åŠ è½½ {exchange}: {len(self.seen_announcements[exchange])} ä¸ªå·²çŸ¥å…¬å‘Š")
    
    def is_listing_announcement(self, title: str, keywords: List[str]) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸Šå¸å…¬å‘Š"""
        title_lower = title.lower()
        
        # é€šç”¨ä¸Šå¸å…³é”®è¯
        common_keywords = [
            'list', 'listing', 'new', 'adds', 'launches', 'trading',
            'ìƒì¥', 'ì‹ ê·œ', 'ãƒªã‚¹ãƒˆ', 'ãƒ­ãƒ¼ãƒ³ãƒ',  # éŸ©è¯­ã€æ—¥è¯­
        ]
        
        all_keywords = keywords + common_keywords
        
        for kw in all_keywords:
            if kw.lower() in title_lower:
                return True
        
        return False
    
    def extract_symbols_from_title(self, title: str) -> List[str]:
        """ä»æ ‡é¢˜æå–ä»£å¸ç¬¦å·"""
        # å¸¸è§æ¨¡å¼
        patterns = [
            r'will list ([A-Z]{2,10})',
            r'lists? ([A-Z]{2,10})',
            r'adds? ([A-Z]{2,10})',
            r'launches? ([A-Z]{2,10})',
            r'\(([A-Z]{2,10})\)',
            r'ã€([A-Z]{2,10})ã€‘',
        ]
        
        symbols = []
        for pattern in patterns:
            matches = re.findall(pattern, title, re.IGNORECASE)
            symbols.extend([m.upper() for m in matches])
        
        # å»é‡
        return list(set(symbols))
    
    async def check_announcements(self, exchange: str, config: dict):
        """æ£€æŸ¥äº¤æ˜“æ‰€å…¬å‘Š"""
        url = config['url']
        method = config['method']
        parser = config['parser']
        keywords = config.get('keywords', [])
        interval = config.get('interval', 10)
        
        if exchange not in self.seen_announcements:
            self.seen_announcements[exchange] = set()
        
        while self.running:
            try:
                # æ„å»ºè¯·æ±‚
                if method == 'GET':
                    params = config.get('params', {})
                    async with self.session.get(url, params=params) as resp:
                        if resp.status == 200:
                            data = await resp.json()
                        else:
                            logger.warning(f"{exchange} å…¬å‘Š API è¿”å› {resp.status}")
                            self.stats['errors'] += 1
                            await asyncio.sleep(interval)
                            continue
                else:  # POST
                    payload = config.get('payload', {})
                    async with self.session.post(url, json=payload) as resp:
                        if resp.status == 200:
                            data = await resp.json()
                        else:
                            logger.warning(f"{exchange} å…¬å‘Š API è¿”å› {resp.status}")
                            self.stats['errors'] += 1
                            await asyncio.sleep(interval)
                            continue
                
                # è§£æå…¬å‘Š
                try:
                    announcements = parser(data)
                except Exception as e:
                    logger.error(f"{exchange} è§£æé”™è¯¯: {e}")
                    self.stats['errors'] += 1
                    await asyncio.sleep(interval)
                    continue
                
                self.stats['announcements_checked'] += len(announcements)
                
                for ann in announcements:
                    ann_id = str(ann.get('id', ''))
                    title = ann.get('title', '')
                    
                    if not ann_id or ann_id in self.seen_announcements[exchange]:
                        continue
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸Šå¸å…¬å‘Š
                    if self.is_listing_announcement(title, keywords):
                        # æå–ä»£å¸ç¬¦å·
                        symbols = self.extract_symbols_from_title(title)
                        
                        # æå–åˆçº¦åœ°å€
                        contract_info = extract_contract_address(title)
                        
                        # åˆ›å»ºäº‹ä»¶
                        event = {
                            'source': f'{exchange}_announcement',
                            'source_type': 'announcement',
                            'exchange': exchange,
                            'symbol': symbols[0] if symbols else '',
                            'symbols': json.dumps(symbols),
                            'raw_text': title,
                            'url': ann.get('url', ''),
                            'contract_address': contract_info.get('contract_address', ''),
                            'chain': contract_info.get('chain', ''),
                            'ts': str(int(time.time() * 1000)),
                            'detected_at': str(int(time.time() * 1000)),
                            'announcement_time': str(ann.get('time', 0)),
                        }
                        
                        # æ¨é€äº‹ä»¶
                        self.redis.push_event('events:raw', event)
                        self.stats['new_listings_found'] += 1
                        
                        # è®°å½•å·²è§
                        self.seen_announcements[exchange].add(ann_id)
                        self.redis.client.sadd(f"seen_announcements:{exchange}", ann_id)
                        
                        logger.info(f"ğŸ”¥ {exchange.upper()} ä¸Šå¸å…¬å‘Š: {title[:60]}...")
                        if symbols:
                            logger.info(f"   ä»£å¸: {', '.join(symbols)}")
                
            except asyncio.TimeoutError:
                logger.warning(f"{exchange} å…¬å‘Šè¯·æ±‚è¶…æ—¶")
                self.stats['errors'] += 1
            except Exception as e:
                logger.error(f"{exchange} å…¬å‘Šç›‘æ§é”™è¯¯: {e}")
                self.stats['errors'] += 1
            
            await asyncio.sleep(interval)
    
    async def heartbeat(self):
        """å¿ƒè·³"""
        while self.running:
            try:
                data = {
                    'status': 'running',
                    'checked': self.stats['announcements_checked'],
                    'found': self.stats['new_listings_found'],
                    'errors': self.stats['errors'],
                }
                self.redis.heartbeat('REALTIME_LISTING', data, ttl=30)
            except:
                pass
            
            await asyncio.sleep(10)
    
    async def stats_reporter(self):
        """ç»Ÿè®¡æŠ¥å‘Š"""
        while self.running:
            await asyncio.sleep(60)
            logger.info(
                f"ğŸ“Š å…¬å‘Šç›‘æ§ç»Ÿè®¡ | æ£€æŸ¥:{self.stats['announcements_checked']} | "
                f"å‘ç°:{self.stats['new_listings_found']} | "
                f"é”™è¯¯:{self.stats['errors']}"
            )
    
    async def run(self):
        """è¿è¡Œç›‘æ§"""
        await self.init()
        
        logger.info("=" * 60)
        logger.info("ğŸ”” å®æ—¶ä¸Šå¸ä¿¡æ¯ç›‘æ§å™¨å¯åŠ¨")
        logger.info(f"   ç›‘æ§ {len(ANNOUNCEMENT_APIS)} ä¸ªäº¤æ˜“æ‰€å…¬å‘Š")
        logger.info("=" * 60)
        
        tasks = []
        
        # å¯åŠ¨å„äº¤æ˜“æ‰€å…¬å‘Šç›‘æ§
        for exchange, config in ANNOUNCEMENT_APIS.items():
            tasks.append(asyncio.create_task(self.check_announcements(exchange, config)))
            logger.info(f"ğŸ“¡ å¯åŠ¨ {exchange} å…¬å‘Šç›‘æ§ (é—´éš” {config.get('interval', 10)}s)")
        
        # å¿ƒè·³å’Œç»Ÿè®¡
        tasks.append(asyncio.create_task(self.heartbeat()))
        tasks.append(asyncio.create_task(self.stats_reporter()))
        
        try:
            await asyncio.gather(*tasks)
        finally:
            self.running = False
            if self.session:
                await self.session.close()
            if self.redis:
                self.redis.close()
    
    def stop(self):
        self.running = False


async def main():
    import signal
    
    monitor = RealtimeListingMonitor()
    
    def signal_handler(sig, frame):
        logger.info("æ”¶åˆ°åœæ­¢ä¿¡å·...")
        monitor.stop()
    
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    await monitor.run()


if __name__ == '__main__':
    asyncio.run(main())

