#!/usr/bin/env python3
"""
Fusion Engine v3 - é¡¶çº§é‡åŒ–æœºæ„è¯„åˆ†ä½“ç³»
======================================

æ ¸å¿ƒå‡çº§ï¼š
1. é›†æˆ InstitutionalScorerï¼ˆæœºæ„çº§è¯„åˆ†å™¨ï¼‰
2. æºåˆ†ç±»ç³»ç»Ÿï¼ˆè‡ªåŠ¨è¯†åˆ«é«˜è´¨é‡æºï¼‰
3. äº¤æ˜“æ‰€ä¹˜æ•°ï¼ˆå¤´éƒ¨äº¤æ˜“æ‰€æƒé‡æ”¾å¤§ï¼‰
4. ä¸¥æ ¼è§¦å‘æ¡ä»¶ï¼ˆTier-Sæº æˆ– å¤šæ‰€ç¡®è®¤ æˆ– é«˜åˆ†ï¼‰
5. è¿‡æ»¤åƒåœ¾å¸äº¤æ˜“æ‰€ï¼ˆMEXCç­‰ä½æƒé‡ï¼‰

è§¦å‘æ¡ä»¶ï¼ˆæ»¡è¶³å…¶ä¸€ï¼‰ï¼š
1. æ¥è‡ª Tier-S æºï¼ˆå®˜æ–¹å…¬å‘Š/é«˜è´¨é‡æƒ…æŠ¥ï¼‰
2. å¤šäº¤æ˜“æ‰€ç¡®è®¤ï¼ˆ2+ ä¸åŒäº¤æ˜“æ‰€ï¼‰
3. final_score >= 40
"""

import asyncio
import threading
import json
import signal
import sys
import os
from datetime import datetime, timezone
from pathlib import Path

# æ·»åŠ  core å±‚è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))
from core.logging import get_logger
from core.redis_client import RedisClient
from core.config import get_config, get_redis_config
from core.utils import extract_contract_address

# YAML ä¸ºå¯é€‰ä¾èµ–
try:
    import yaml
    HAS_YAML = True
except ImportError:
    HAS_YAML = False

# å¯¼å…¥æœºæ„çº§è¯„åˆ†å™¨
from .scoring_engine import InstitutionalScorer, TIER_S_SOURCES, TRIGGER_THRESHOLD

logger = get_logger('fusion_engine')


class SuperEventAggregator:
    """
    è¶…çº§äº‹ä»¶èšåˆå™¨
    åœ¨æ—¶é—´çª—å£å†…åˆå¹¶åŒä¸€ symbol çš„å¤šæºäº‹ä»¶
    """
    
    def __init__(self, window_seconds: int = 5):
        self.window_seconds = window_seconds
        self.pending_events = {}  # symbol -> aggregated_event
        self.pending_timestamps = {}  # symbol -> first_seen_time
    
    def should_aggregate(self, symbol: str, current_time: float) -> bool:
        if symbol not in self.pending_timestamps:
            return False
        return (current_time - self.pending_timestamps[symbol]) < self.window_seconds
    
    def add_event(self, symbol: str, event: dict, score_info: dict, current_time: float):
        if not symbol:
            return None
        
        if self.should_aggregate(symbol, current_time):
            # åˆå¹¶åˆ°ç°æœ‰äº‹ä»¶
            existing = self.pending_events[symbol]
            
            # æ›´æ–°æœ€é«˜åˆ†
            if score_info['total_score'] > existing['max_score']:
                existing['max_score'] = score_info['total_score']
                existing['best_event'] = event
                existing['best_score_info'] = score_info
            
            # ç´¯åŠ æºå’Œäº¤æ˜“æ‰€
            existing['sources'].add(event.get('source', 'unknown'))
            if event.get('exchange'):
                existing['exchanges'].add(event.get('exchange', '').lower())
            
            existing['event_count'] += 1
            existing['source_count'] = len(existing['sources'])
            existing['exchange_count'] = len(existing['exchanges'])
            
            # è®¡ç®—å¤šæºåŠ åˆ†
            multi_bonus = min((existing['source_count'] - 1) * 15, 50) if existing['source_count'] >= 2 else 0
            existing['multi_bonus'] = multi_bonus
            existing['final_score'] = existing['max_score'] + multi_bonus
            existing['is_super_event'] = existing['source_count'] >= 2 or existing['exchange_count'] >= 2
            
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥ç«‹å³è¾“å‡ºï¼ˆå¤šæºç¡®è®¤ï¼‰
            if existing['exchange_count'] >= 2:
                result = existing.copy()
                result['sources'] = list(existing['sources'])
                result['exchanges'] = list(existing['exchanges'])
                del self.pending_events[symbol]
                del self.pending_timestamps[symbol]
                return result
            
            return None
        else:
            # æ–°äº‹ä»¶ï¼Œå¼€å§‹èšåˆ
            exchange = event.get('exchange', '').lower()
            self.pending_events[symbol] = {
                'symbol': symbol,
                'sources': {event.get('source', 'unknown')},
                'exchanges': {exchange} if exchange else set(),
                'best_event': event,
                'best_score_info': score_info,
                'max_score': score_info['total_score'],
                'final_score': score_info['total_score'],
                'event_count': 1,
                'source_count': 1,
                'exchange_count': 1 if exchange else 0,
                'multi_bonus': 0,
                'is_super_event': False,
                'first_seen': current_time,
            }
            self.pending_timestamps[symbol] = current_time
            return None
    
    def flush_expired(self, current_time: float) -> list:
        """åˆ·æ–°è¿‡æœŸçš„å¾…å¤„ç†äº‹ä»¶"""
        expired = []
        to_delete = []
        
        for symbol, ts in self.pending_timestamps.items():
            if current_time - ts >= self.window_seconds:
                if symbol in self.pending_events:
                    evt = self.pending_events[symbol]
                    evt['sources'] = list(evt['sources'])
                    evt['exchanges'] = list(evt['exchanges'])
                    expired.append(evt)
                to_delete.append(symbol)
        
        for symbol in to_delete:
            self.pending_events.pop(symbol, None)
            self.pending_timestamps.pop(symbol, None)
        
        return expired


class FusionEngineV3:
    """Fusion Engine v3 - æœºæ„çº§è¯„åˆ†"""
    
    def __init__(self, config_path: str = 'config.yaml'):
        # å°è¯•åŠ è½½ YAML é…ç½®æ–‡ä»¶
        self.config = {}
        if HAS_YAML and Path(config_path).exists():
            with open(config_path) as f:
                self.config = yaml.safe_load(f) or {}
        
        # è¿æ¥ Redisï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®ï¼‰
        self.redis = RedisClient.from_env()
        
        # ä½¿ç”¨æœºæ„çº§è¯„åˆ†å™¨
        self.scorer = InstitutionalScorer()
        self.aggregator = SuperEventAggregator(window_seconds=5)
        self.running = True
        self.stats = {
            'processed': 0,
            'fused': 0,
            'triggered': 0,
            'duplicates': 0,
            'filtered': 0,
        }
        
        logger.info("âœ… Fusion Engine v3 (æœºæ„çº§è¯„åˆ†) åˆå§‹åŒ–å®Œæˆ")
    
    def format_fused_event(self, event: dict, score_info: dict) -> dict:
        """æ ¼å¼åŒ–èåˆäº‹ä»¶"""
        raw_text = event.get('raw_text', '') or event.get('text', '') or event.get('title', '')
        
        # ğŸ†• è·å–åˆçº¦åœ°å€ï¼ˆä¼˜å…ˆä½¿ç”¨ Collector å·²æå–çš„ï¼Œå¦åˆ™ä» raw_text æå–ï¼‰
        contract_address = event.get('contract_address', '')
        chain = event.get('chain', '')
        
        if not contract_address and raw_text:
            # ä»åŸå§‹æ–‡æœ¬ä¸­æå–åˆçº¦åœ°å€
            contract_info = extract_contract_address(raw_text)
            contract_address = contract_info.get('contract_address', '')
            chain = contract_info.get('chain', '')
        
        return {
            # åŸºç¡€ä¿¡æ¯
            'source': score_info['classified_source'],
            'original_source': event.get('source', 'unknown'),
            'event_type': 'new_listing',
            'exchange': event.get('exchange', ''),
            'symbols': ','.join(score_info['symbols']) if score_info['symbols'] else '',
            
            # åŸå§‹å†…å®¹
            'raw_text': raw_text,
            'url': event.get('url', ''),
            
            # ğŸ†• åˆçº¦åœ°å€å­—æ®µ
            'contract_address': contract_address or '',
            'chain': chain or '',
            
            # ç¤¾äº¤åª’ä½“å­—æ®µ
            'account': event.get('account', ''),
            'channel': event.get('channel', '') or event.get('channel_id', ''),
            
            # æ–°é—»å­—æ®µ
            'title': event.get('title', ''),
            'news_source': event.get('news_source', ''),
            'summary': event.get('summary', ''),
            
            # v3 è¯„åˆ†ä¿¡æ¯
            'score': str(score_info['total_score']),
            'base_score': str(score_info['base_score']),
            'exchange_multiplier': str(score_info['exchange_multiplier']),
            'freshness_multiplier': str(score_info['freshness_multiplier']),
            'multi_source_bonus': str(score_info['multi_source_bonus']),
            'source_count': str(score_info['source_count']),
            'exchange_count': str(score_info['exchange_count']),
            
            # è§¦å‘ä¿¡æ¯
            'should_trigger': '1' if score_info['should_trigger'] else '0',
            'trigger_reason': score_info['trigger_reason'],
            'is_first': '1' if score_info['is_first'] else '0',
            
            # æ—¶é—´æˆ³
            'ts': str(int(datetime.now(timezone.utc).timestamp() * 1000)),
            
            # å…¼å®¹å­—æ®µ
            'symbol_hint': json.dumps(score_info['symbols']),
            'score_detail': json.dumps({
                'base': score_info['base_score'],
                'exchange_mult': score_info['exchange_multiplier'],
                'fresh_mult': score_info['freshness_multiplier'],
                'multi_bonus': score_info['multi_source_bonus'],
                'classified_source': score_info['classified_source'],
            }),
            '_fusion': json.dumps({
                'source_confidence': score_info['total_score'] / 100,
                'source_count': score_info['source_count'],
                'exchange_count': score_info['exchange_count'],
                'trigger_reason': score_info['trigger_reason'],
            }),
        }
    
    def format_super_event(self, super_event: dict) -> dict:
        """æ ¼å¼åŒ–è¶…çº§äº‹ä»¶ï¼ˆå¤šæºåˆå¹¶ï¼‰"""
        best_event = super_event['best_event']
        score_info = super_event['best_score_info']
        raw_text = best_event.get('raw_text', '') or best_event.get('text', '')
        
        # åˆ¤æ–­æ˜¯å¦è§¦å‘
        should_trigger = super_event['exchange_count'] >= 2 or super_event['final_score'] >= TRIGGER_THRESHOLD
        if super_event['exchange_count'] >= 2:
            trigger_reason = f"å¤šæ‰€ç¡®è®¤({super_event['exchange_count']}æ‰€)"
        elif super_event['final_score'] >= TRIGGER_THRESHOLD:
            trigger_reason = f"é«˜åˆ†({super_event['final_score']:.0f})"
        else:
            trigger_reason = "æœªè¾¾æ ‡"
        
        # ğŸ†• è·å–åˆçº¦åœ°å€
        contract_address = best_event.get('contract_address', '')
        chain = best_event.get('chain', '')
        
        if not contract_address and raw_text:
            contract_info = extract_contract_address(raw_text)
            contract_address = contract_info.get('contract_address', '')
            chain = contract_info.get('chain', '')
        
        return {
            # åŸºç¡€ä¿¡æ¯
            'source': ','.join(super_event['sources']),
            'event_type': 'new_listing_confirmed' if super_event['is_super_event'] else 'new_listing',
            'exchange': ','.join(super_event['exchanges']),
            'symbols': super_event['symbol'],
            
            # åŸå§‹å†…å®¹
            'raw_text': raw_text,
            'url': best_event.get('url', ''),
            
            # ğŸ†• åˆçº¦åœ°å€å­—æ®µ
            'contract_address': contract_address or '',
            'chain': chain or '',
            
            # è¶…çº§äº‹ä»¶å­—æ®µ
            'is_super_event': '1' if super_event['is_super_event'] else '0',
            'source_count': str(super_event['source_count']),
            'exchange_count': str(super_event['exchange_count']),
            'event_count': str(super_event['event_count']),
            'multi_bonus': str(super_event['multi_bonus']),
            
            # v3 è¯„åˆ†
            'score': str(super_event['final_score']),
            'base_score': str(score_info['base_score']),
            
            # è§¦å‘ä¿¡æ¯
            'should_trigger': '1' if should_trigger else '0',
            'trigger_reason': trigger_reason,
            'is_first': '1' if score_info['is_first'] else '0',
            
            # æ—¶é—´æˆ³
            'ts': str(int(datetime.now(timezone.utc).timestamp() * 1000)),
            
            # å…¼å®¹å­—æ®µ
            'symbol_hint': json.dumps([super_event['symbol']]),
            'score_detail': json.dumps({
                'sources': super_event['sources'],
                'exchanges': super_event['exchanges'],
                'multi_bonus': super_event['multi_bonus'],
            }),
            '_fusion': json.dumps({
                'source_confidence': super_event['final_score'] / 100,
                'source_count': super_event['source_count'],
                'exchange_count': super_event['exchange_count'],
                'is_super_event': super_event['is_super_event'],
                'trigger_reason': trigger_reason,
            }),
        }
    
    async def process_events(self):
        """å¤„ç†äº‹ä»¶æµ"""
        # è·å– stream é…ç½®ï¼ˆå¸¦é»˜è®¤å€¼ï¼‰
        stream_cfg = self.config.get('stream', {})
        stream_name = stream_cfg.get('raw_events', 'events:raw')
        output_stream = stream_cfg.get('fused_events', 'events:fused')
        
        # è·å–æ¶ˆè´¹è€…é…ç½®
        fusion_cfg = self.config.get('fusion', {})
        consumer_group = fusion_cfg.get('consumer_group', 'fusion_group')
        consumer_name = fusion_cfg.get('consumer_name', 'fusion_consumer')
        
        try:
            self.redis.create_consumer_group(stream_name, consumer_group)
        except:
            pass
        
        logger.info(f"ğŸ“¡ å¼€å§‹æ¶ˆè´¹ {stream_name}")
        
        while self.running:
            try:
                events = self.redis.consume_stream(
                    stream_name, consumer_group, consumer_name,
                    count=10, block=1000
                )
                
                if not events:
                    continue
                
                import time
                current_time = time.time()
                
                # å…ˆåˆ·æ–°è¿‡æœŸäº‹ä»¶
                expired_events = self.aggregator.flush_expired(current_time)
                for exp_evt in expired_events:
                    exp_fused = self.format_super_event(exp_evt)
                    
                    # åªè¾“å‡ºè§¦å‘çš„äº‹ä»¶
                    if exp_fused['should_trigger'] == '1':
                        self.redis.push_event(output_stream, exp_fused)
                        self.stats['fused'] += 1
                        self.stats['triggered'] += 1
                        
                        if exp_evt['is_super_event']:
                            logger.info(
                                f"ğŸ”¥ è¶…çº§äº‹ä»¶: {exp_evt['symbol']} | "
                                f"{exp_evt['exchange_count']}æ‰€ç¡®è®¤ | "
                                f"åˆ†æ•°{exp_evt['final_score']:.0f}"
                            )
                    else:
                        self.stats['filtered'] += 1
                
                for stream, messages in events:
                    for message_id, raw_msg in messages:
                        self.stats['processed'] += 1
                        
                        # è§£æ JSONï¼ˆevent_data å­—æ®µæ˜¯ JSON å­—ç¬¦ä¸²ï¼‰
                        try:
                            if 'event_data' in raw_msg:
                                event_data = json.loads(raw_msg['event_data'])
                            else:
                                event_data = raw_msg  # å…¼å®¹æ—§æ ¼å¼
                        except (json.JSONDecodeError, TypeError) as e:
                            logger.warning(f"JSON è§£æå¤±è´¥: {e}")
                            self.redis.ack_message(stream_name, consumer_group, message_id)
                            continue
                        
                        # å»é‡
                        if self.scorer.is_duplicate(event_data):
                            self.stats['duplicates'] += 1
                            self.redis.ack_message(stream_name, consumer_group, message_id)
                            continue
                        
                        # è®¡ç®—è¯„åˆ†
                        score_info = self.scorer.calculate_score(event_data)
                        
                        # æå– symbol ç”¨äºèšåˆ
                        symbols = score_info.get('symbols', [])
                        primary_symbol = symbols[0] if symbols else ''
                        
                        # å°è¯•èšåˆ
                        super_event = self.aggregator.add_event(
                            primary_symbol, event_data, score_info, current_time
                        )
                        
                        if super_event:
                            # å¤šæºç¡®è®¤ï¼Œç«‹å³è¾“å‡º
                            fused_event = self.format_super_event(super_event)
                            
                            if fused_event['should_trigger'] == '1':
                                self.redis.push_event(output_stream, fused_event)
                                self.stats['fused'] += 1
                                self.stats['triggered'] += 1
                                
                                logger.info(
                                    f"ğŸ”¥ å¤šæ‰€ç¡®è®¤: {super_event['symbol']} | "
                                    f"{super_event['exchanges']} | "
                                    f"åˆ†æ•°{super_event['final_score']:.0f}"
                                )
                            else:
                                self.stats['filtered'] += 1
                        
                        elif score_info['should_trigger']:
                            # å•æºä½†æ»¡è¶³è§¦å‘æ¡ä»¶ï¼ˆTier-Sæºæˆ–é«˜åˆ†ï¼‰
                            fused_event = self.format_fused_event(event_data, score_info)
                            self.redis.push_event(output_stream, fused_event)
                            self.stats['fused'] += 1
                            self.stats['triggered'] += 1
                            
                            symbol_str = symbols[0] if symbols else 'N/A'
                            logger.info(
                                f"âœ… {score_info['trigger_reason']} | "
                                f"{score_info['classified_source']} | "
                                f"{symbol_str} | "
                                f"åˆ†æ•°{score_info['total_score']:.0f}"
                            )
                        else:
                            # ä¸æ»¡è¶³è§¦å‘æ¡ä»¶ï¼Œç­‰å¾…èšåˆæˆ–è¿‡æ»¤
                            self.stats['filtered'] += 1
                        
                        # ACK
                        self.redis.ack_message(stream_name, consumer_group, message_id)
                
            except Exception as e:
                logger.error(f"å¤„ç†é”™è¯¯: {e}")
                import traceback
                traceback.print_exc()
                await asyncio.sleep(1)
    
    async def stats_reporter(self):
        """å®šæœŸæŠ¥å‘Šç»Ÿè®¡"""
        while self.running:
            await asyncio.sleep(300)
            logger.info(
                f"ğŸ“Š ç»Ÿè®¡ | å¤„ç†:{self.stats['processed']} | "
                f"è§¦å‘:{self.stats['triggered']} | "
                f"è¿‡æ»¤:{self.stats['filtered']} | "
                f"é‡å¤:{self.stats['duplicates']}"
            )
    
    def start_heartbeat_thread(self):
        """å¿ƒè·³çº¿ç¨‹"""
        def heartbeat_worker():
            import time
            while self.running:
                try:
                    heartbeat_data = {
                        "status": "running",
                        "version": "v3",
                        "processed": self.stats["processed"],
                        "triggered": self.stats["triggered"],
                        "filtered": self.stats["filtered"],
                    }
                    self.redis.heartbeat("fusion", heartbeat_data, ttl=120)
                except Exception as e:
                    logger.warning(f"å¿ƒè·³å¤±è´¥: {e}")
                time.sleep(10)
        
        t = threading.Thread(target=heartbeat_worker, daemon=True)
        t.start()
        logger.info("âœ… å¿ƒè·³çº¿ç¨‹å·²å¯åŠ¨")
    
    async def run(self):
        """è¿è¡Œå¼•æ“"""
        self.start_heartbeat_thread()
        logger.info("=" * 60)
        logger.info("Fusion Engine v3 (æœºæ„çº§è¯„åˆ†) å¯åŠ¨")
        logger.info(f"è§¦å‘é˜ˆå€¼: {TRIGGER_THRESHOLD} | Tier-Sæº: {len(TIER_S_SOURCES)}ä¸ª")
        logger.info("=" * 60)
        
        tasks = [
            self.process_events(),
            self.stats_reporter(),
        ]
        await asyncio.gather(*tasks)


# å…¨å±€å˜é‡
engine = None
running = True

def signal_handler(signum, frame):
    global running
    logger.info("æ”¶åˆ°åœæ­¢ä¿¡å·...")
    running = False
    if engine:
        engine.running = False

async def main():
    global engine
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    engine = FusionEngineV3()
    await engine.run()

if __name__ == '__main__':
    asyncio.run(main())
