#!/usr/bin/env python3
"""
Webhook Pusher - Push fused events to n8n
ä»Redisè¯»å–èåˆäº‹ä»¶ï¼Œæ¨é€åˆ°n8n webhook
ä¿æŒä¸ç°æœ‰n8næ ¼å¼å…¼å®¹
"""

from .wechat_pusher import send_wechat
import asyncio
import aiohttp
import json
import yaml
import sys
import signal
from datetime import datetime, timezone
from pathlib import Path

# æ·»åŠ  core å±‚è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))
from core.logging import get_logger
from core.redis_client import RedisClient

# é…ç½®
import os
from dotenv import load_dotenv
load_dotenv()

logger = get_logger('webhook_pusher')

# å…¨å±€å˜é‡
redis_client = None
config = None
running = True
stats = {
    'events_processed': 0,
    'webhooks_sent': 0,
    'webhooks_failed': 0,
    'retries': 0
}


def load_config():
    """ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®"""
    global config
    webhook_url = os.getenv('WECHAT_WEBHOOK') or os.getenv('WECHAT_WEBHOOK_SIGNAL') or os.getenv('WEBHOOK_URL', '')
    
    config = {
        'webhook': {
            'url': webhook_url,
            'timeout': 10,
            'retry_times': 3,
        },
        'stream': {
            'fused_events': 'events:fused',
        }
    }
    
    if webhook_url:
        logger.info(f"Webhook é…ç½®åŠ è½½æˆåŠŸ: {webhook_url[:50]}...")
    else:
        logger.warning("æœªé…ç½® WEBHOOK_URL ç¯å¢ƒå˜é‡")


def format_for_n8n(fused_event):
    """
    æ ¼å¼åŒ–ä¸ºn8nå…¼å®¹æ ¼å¼
    ä¿æŒç°æœ‰å­—æ®µï¼Œæ·»åŠ å¯é€‰çš„_fusionå­—æ®µ
    """
    # åŸºç¡€å­—æ®µï¼ˆn8nç°æœ‰æ ¼å¼ï¼‰
    n8n_payload = {
        'source': fused_event.get('source', 'fusion_engine'),
        'raw_text': fused_event.get('raw_text', ''),
        'symbol_hint': fused_event.get('symbol_hint', []),
        'exchange': fused_event.get('exchange', ''),
        'url': fused_event.get('url', ''),
        'ts': fused_event.get('ts', int(datetime.now(timezone.utc).timestamp() * 1000))
    }
    
    # å¯é€‰ï¼šæ·»åŠ èåˆå…ƒæ•°æ®
    # Strategy Generatorå¯ä»¥æ ¹æ®source_confidenceè°ƒæ•´ä»“ä½
    if '_fusion' in fused_event:
        n8n_payload['_fusion'] = fused_event['_fusion']
    
    return n8n_payload


async def send_webhook(session, payload, retry_count=0):
    """å‘é€webhookåˆ°n8n"""
    webhook_config = config['webhook']
    url = webhook_config['url']
    max_retries = webhook_config['retry_times']
    timeout = webhook_config['timeout']
    
    try:
        async with session.post(
            url,
            json=payload,
            timeout=aiohttp.ClientTimeout(total=timeout)
        ) as resp:
            if resp.status == 200:
                stats['webhooks_sent'] += 1
                logger.info(
                    f"âœ… Webhookå‘é€æˆåŠŸ: {payload.get('exchange', 'N/A')} - "
                    f"{','.join(payload.get('symbol_hint', [])[:3])}"
                )
                return True
            else:
                logger.warning(f"Webhookè¿”å›é200: {resp.status}")
                stats['webhooks_failed'] += 1
                
                # é‡è¯•
                if retry_count < max_retries:
                    stats['retries'] += 1
                    await asyncio.sleep(2 ** retry_count)  # æŒ‡æ•°é€€é¿
                    return await send_webhook(session, payload, retry_count + 1)
                
                return False
                
    except asyncio.TimeoutError:
        logger.error(f"Webhookè¶…æ—¶ (å°è¯• {retry_count + 1}/{max_retries + 1})")
        stats['webhooks_failed'] += 1
        
        # é‡è¯•
        if retry_count < max_retries:
            stats['retries'] += 1
            await asyncio.sleep(2 ** retry_count)
            return await send_webhook(session, payload, retry_count + 1)
        
        return False
        
    except Exception as e:
        logger.error(f"Webhookå‘é€é”™è¯¯: {e}")
        stats['webhooks_failed'] += 1
        
        # é‡è¯•
        if retry_count < max_retries:
            stats['retries'] += 1
            await asyncio.sleep(2 ** retry_count)
            return await send_webhook(session, payload, retry_count + 1)
        
        return False


async def process_fused_events():
    """å¤„ç†èåˆäº‹ä»¶æµ"""
    logger.info("å¯åŠ¨Webhookæ¨é€å™¨")
    
    stream_name = config['stream']['fused_events']
    consumer_group = 'webhook_pusher_group'
    consumer_name = 'webhook_pusher_1'
    
    # åˆ›å»ºæ¶ˆè´¹è€…ç»„ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    try:
        redis_client.create_consumer_group(stream_name, consumer_group)
    except:
        pass
    
    async with aiohttp.ClientSession() as session:
        while running:
            try:
                # è¯»å–èåˆäº‹ä»¶
                events = redis_client.consume_stream(
                    stream_name,
                    consumer_group,
                    consumer_name,
                    count=10,
                    block=1000
                )
                
                if not events:
                    continue
                
                for stream, messages in events:
                    for message_id, event_data in messages:
                        try:
                            stats['events_processed'] += 1
                            
                            # æ ¼å¼åŒ–ä¸ºn8næ ¼å¼
                            payload = format_for_n8n(event_data)
                            
                            # å‘é€webhook
                            success = await send_webhook(session, payload)
                            await send_wechat(session, event_data)
                            
                            # ACKæ¶ˆæ¯
                            redis_client.ack_message(stream_name, consumer_group, message_id)
                            
                        except Exception as e:
                            logger.error(f"å¤„ç†æ¶ˆæ¯é”™è¯¯: {e}")
                
            except Exception as e:
                logger.error(f"æ¶ˆè´¹äº‹ä»¶é”™è¯¯: {e}")
                await asyncio.sleep(1)


async def heartbeat_loop():
    """å¿ƒè·³ä¸ŠæŠ¥"""
    while running:
        try:
            heartbeat_data = {
                'node': 'WEBHOOK',
                'status': 'online',
                'timestamp': int(datetime.now(timezone.utc).timestamp()),
                'stats': json.dumps(stats)
            }
            
            redis_client.heartbeat('WEBHOOK', heartbeat_data, ttl=120)  # 2åˆ†é’Ÿè¿‡æœŸ
            
        except Exception as e:
            logger.error(f"å¿ƒè·³ä¸ŠæŠ¥å¤±è´¥: {e}")
        
        await asyncio.sleep(30)


async def main():
    """ä¸»å‡½æ•°"""
    global redis_client, running
    
    logger.info("=" * 60)
    logger.info("Webhook Pusher å¯åŠ¨")
    logger.info("=" * 60)
    
    # åŠ è½½é…ç½®
    load_config()
    
    # è¿æ¥ Redisï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®ï¼‰
    redis_client = RedisClient.from_env()
    logger.info("âœ… Redisè¿æ¥æˆåŠŸ")
    
    # æ˜¾ç¤ºwebhook URL
    webhook_url = config['webhook']['url']
    logger.info(f"ğŸ“¡ Webhook URL: {webhook_url}")
    
    # å¯åŠ¨ä»»åŠ¡
    tasks = [
        asyncio.create_task(process_fused_events()),
        asyncio.create_task(heartbeat_loop())
    ]
    
    logger.info(f"âœ… å¯åŠ¨ {len(tasks)} ä¸ªä»»åŠ¡")
    
    # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡
    try:
        await asyncio.gather(*tasks)
    except Exception as e:
        logger.error(f"ä¸»å¾ªç¯é”™è¯¯: {e}")
    finally:
        running = False
        if redis_client:
            redis_client.close()
        logger.info("Webhook Pusher å·²åœæ­¢")


def signal_handler(sig, frame):
    """ä¿¡å·å¤„ç†"""
    global running
    logger.info("æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨å…³é—­...")
    running = False


if __name__ == '__main__':
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"è‡´å‘½é”™è¯¯: {e}")
        sys.exit(1)
